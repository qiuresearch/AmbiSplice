# defaults:
#   - _self_
stage: train
debug: false
gpus: [0]
accelerator: gpu
run_name: ${model.type}_${dataset.type}
project: GWSplice
infer: # used for eval/test/predict only
  save_prefix: dummy
  save_level: 2 # 0: nothing, 1: summary metrics, 2: model outputs, 3: calc and save individual sample metrics
  eval_dim: null # null or a single dim for evaluating each slice along this dim
ensemble: # used for eval/test/predict only
  enable: false
  model:
    type: [null]
    state_dict_path:
      - null
  litrun:
    seed: null
    resume_from_ckpt:
      - null
dataset:
  debug: ${debug}
  stage: ${stage}
  type: PangolinSolo  # PangolinSolo, Pangolin, GeneSites, GeneCrops
  train_path: null
  val_path: null
  test_path: null
  predict_path: null
  split_seed: 111
  train_epoch_length: null
  val_epoch_length: null
  test_epoch_length: null
  predict_epoch_length: null
  enable_cache: false
model:
  debug: ${debug}
  type: null
  dropout: 0.1
  loss: cls+psi
  loss_scale_cls: 0.5
  loss_scale_psi: 0.5
  state_dict_path: null
datamodule: # Datamodule + Dataloader + Sampler configs
  debug: ${debug}
  train_batch_size: 64
  val_batch_size: 96
  test_batch_size: 96
  predict_batch_size: 96
  train_shuffle: true
  val_shuffle: false
  test_shuffle: false
  predict_shuffle: false
  batch_sampler: null
  num_workers: 4
  prefetch_factor: 7
litrun:
  debug: ${debug}
  seed: 1234
  resume_from_ckpt: null
  resume_model_weights_only: true
  optimizer:
    learning_rate: 0.0007
    eps: 1e-8
    lr_scheduler: CosineAnnealingWarmRestarts
    lr_interval: epoch
    lr_T_0: 3
    lr_T_mult: 2
    last_lr_step: -1
  trainer:
    overfit_batches: 0 # 0 means all batches used
    min_epochs: 3
    max_epochs: 21
    max_time: "7:00:00:00"  # D:HH:MM:SS
    strategy: auto
    precision: 32
    deterministic: false
    log_every_n_steps: 1
    num_sanity_val_steps: 0
    check_val_every_n_epoch: 1
    accumulate_grad_batches: 1
  wandb:
    name: ${run_name} # date-time will be appended automatically
    project: ${project}
    save_code: false
    tags: []
    mode: online # online, offline, disabled
  early_stopping:
    monitor: val_loss
    mode: min
    patience: 11
    strict: true
    verbose: true
  lr_monitor:
    logging_interval: step
    log_momentum: false
  checkpoints:
    dirpath: checkpoints # wandb name will be appended automatically
    filename: 'valoss-{val_loss:.6f}_epoch-{epoch:03d}_step-{step:06d}'
    auto_insert_metric_name: false
    save_weights_only: false
    save_last: true
    save_top_k: -1 # 0: no model saved; -1: all models saved
    monitor: val_loss
    mode: min
    every_n_epochs: 1
    every_n_train_steps: null